{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Run the next cell\n",
        "\n",
        "you need T4 gpu to be able to test the model"
      ],
      "metadata": {
        "id": "ToPD6zvQuXCE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXzIEAZRuR0Q"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Tacotron and Waveglow (click to see code)\n",
        "\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "!pip install gdown\n",
        "git_repo_url = 'https://github.com/maxmelichov/tacotron2.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # clone and install\n",
        "  !git clone -q --recursive {git_repo_url}\n",
        "  !cd {project_name}/waveglow && git checkout 2fd4e63\n",
        "  !pip install -q librosa unidecode\n",
        "  !pip install Hebrew\n",
        "  \n",
        "import sys\n",
        "sys.path.append(join(project_name, 'waveglow/'))\n",
        "sys.path.append(project_name)\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "import gdown\n",
        "from hebrew import Hebrew\n",
        "from hebrew.chars import HebrewChar, ALEPH\n",
        "from hebrew import GematriaTypes\n",
        "d = 'https://drive.google.com/uc?id='"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NatDNxccuUmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pre-trained model"
      ],
      "metadata": {
        "id": "TaPJp2QNut8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Tacotron pretrained model\n",
        "force_download_TT2 = True\n",
        "tacotron2_pretrained_model = 'MLPTTS'\n",
        "if not exists(tacotron2_pretrained_model) or force_download_TT2:\n",
        "                   # ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ PUT MODEL HERE\n",
        "  gdown.download(d+r'1ByWFnQsqIZuJpz7PgBgCo4ED63eFyKKp&export=download', tacotron2_pretrained_model, quiet=False); print(\"Tacotron2 Model Downloaded\")\n",
        "                   # ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ PUT MODEL HERE\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wgu8WXVkuqtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Waveglow pretrained\n",
        "waveglow_pretrained_model = 'waveglow.pt'\n",
        "if not exists(waveglow_pretrained_model):\n",
        "  gdown.download(d+r'1rpK8CzAAirq9sWZhe9nlfvxMF1dRgFbF&export=download', waveglow_pretrained_model, quiet=False); print(\"WaveGlow Model Downloaded\")#1okuUstGoBe_qZ4qUEF8CcwEugHP7GM_b&export"
      ],
      "metadata": {
        "cellView": "form",
        "id": "f_eOD7Kyu6bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./tacotron2/waveglow/convert_model.py /content/waveglow.pt /content/waveglow.pt"
      ],
      "metadata": {
        "id": "GKkUcNRsu9sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "locale.getpreferredencoding()"
      ],
      "metadata": {
        "id": "uvqhtbjru_l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize Tacotron and Waveglow and Hebrew to English fucntion\n",
        "%matplotlib inline\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from hparams import create_hparams\n",
        "from model import Tacotron2\n",
        "from layers import TacotronSTFT\n",
        "from audio_processing import griffin_lim\n",
        "from text import text_to_sequence\n",
        "from denoiser import Denoiser\n",
        "\n",
        "graph_width = 900\n",
        "graph_height = 360\n",
        "def plot_data(data, figsize=(int(graph_width/100), int(graph_height/100))):\n",
        "    %matplotlib inline\n",
        "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
        "    for i in range(len(data)):\n",
        "        axes[i].imshow(data[i], aspect='auto', origin='upper', \n",
        "                       interpolation='none', cmap='inferno')\n",
        "    fig.canvas.draw()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        " \n",
        " \n",
        "##breaks down number to digits\n",
        "def breakdown(number):\n",
        "    digits = []\n",
        "    for place, value in zip([1000, 100, 10, 1], [1000, 100, 10, 1]):\n",
        "        digit = number // place * value\n",
        "        digits.append(digit)\n",
        "        number -= digit\n",
        "    return digits\n",
        " \n",
        "##turns number to hebrew\n",
        "def NumberToHebrew(number):\n",
        " \n",
        "    if number==0:\n",
        "        return \"אֶפֶס\"\n",
        " \n",
        "    num_dict_below_20={\n",
        "        1: 'אֶחָד',\n",
        "        2: 'שְׁנַיִם',\n",
        "        3: 'שְׁלֹשָׁה',\n",
        "        4: 'אַרְבָּעָה',\n",
        "        5: 'חֲמִשָּׁה',\n",
        "        6: 'שִׁשָּׁה',\n",
        "        7: 'שִׁבְעָה',\n",
        "        8: 'שְׁמוֹנָה',\n",
        "        9: 'תִּשְׁעָה',\n",
        "        10: 'עֶשֶׂר',\n",
        "        11: 'אַחַד עָשָׂר',\n",
        "        12: 'שְׁנֵים עָשָׂר',\n",
        "        13: 'שְׁלֹשָׁה עָשָׂר',\n",
        "        14: 'אַרְבָּעָה עָשָׂר',\n",
        "        15: 'חֲמִשָּׁה עָשָׂר',\n",
        "        16: 'שִׁשָּׁה עָשָׂר',\n",
        "        17: \"שִׁבְעָה עֶשְׂרֵה\",\n",
        "        18: \"שְׁמוֹנָה עֶשְׂרֵה\",\n",
        "        19: \"תִּשְׁעָה עֶשְׂרֵה\"\n",
        "    }\n",
        " \n",
        "    num_dict_eq_above_20={\n",
        "        20: \"עֶשְׂרִים\",\n",
        "        30: \"שְׁלשִׁים\",\n",
        "        40: \"אַרְבָּעִים\",\n",
        "        50: \"חֲמִשִּׁים\",\n",
        "        60: \"שִׁשִּׁים\",\n",
        "        70: \"שִׁבְעִים\",\n",
        "        80: \"שְׁמוֹנִים\",\n",
        "        90: \"תִּשְׁעִים\",\n",
        "        100: \"מֵאָה\",\n",
        "        200: \"מָאתַיִם\",\n",
        "        300: \"שְׁלֹשׁ מֵאוֹת\",\n",
        "        400: \"אַרְבָּעִ מֵאוֹת\",\n",
        "        500: \"חֲמִשֶּׁ מֵאוֹת\",\n",
        "        600: \"שֵׁשׁ מֵאוֹת\",\n",
        "        700: \"שִׁבְעַ מֵאוֹת\",\n",
        "        800: \"שְׁמוֹנֶ מֵאוֹת\",\n",
        "        900: \"תִּשְׁעַ מֵאוֹת\",\n",
        "        1000: \"אֶלֶף\",\n",
        "        2000: \"אֲלַפַּיִם\",\n",
        "        3000: \"שְׁלֹשֶׁת אֲלָפִים\",\n",
        "        4000: \"אַרְבַּעַת אֲלָפִים\",\n",
        "        5000: \"חֲמֵשׁ אֲלָפִים\",\n",
        "        6000: \"שֵׁשׁ אֲלָפִים\",\n",
        "        7000: \"שִׁבְעָה אֲלָפִים\",\n",
        "        8000: \"שְׁמוֹנָה אֲלָפִים\",\n",
        "        9000: \"תִּשְׁעָה אֲלָפִים\"\n",
        "    }\n",
        " \n",
        "    list_heb=[]\n",
        "    list_num=breakdown(number)\n",
        " \n",
        "    for i,num in enumerate(list_num):\n",
        "        if num==0:\n",
        "            continue\n",
        "        else:\n",
        "            if i<2:\n",
        "                list_heb.append(num_dict_eq_above_20[num])\n",
        " \n",
        "            elif i==2:\n",
        "                if list_num[0]!=0 or list_num[1]!=0:\n",
        "                    if list_num[2]+list_num[3]<20:\n",
        "                        list_heb.append(\"וְ\"+num_dict_below_20[list_num[2]+list_num[3]])\n",
        "                        break\n",
        "                    else:\n",
        "                        list_heb.append(num_dict_eq_above_20[num])\n",
        "                else:\n",
        "                    if list_num[2] + list_num[3] < 20:\n",
        "                        list_heb.append(num_dict_below_20[list_num[2] + list_num[3]])\n",
        "                        break\n",
        "                    else:\n",
        "                        list_heb.append(num_dict_eq_above_20[num])\n",
        " \n",
        "            elif i==3:\n",
        "                if list_num[0]!=0 or list_num[1]!=0 or list_num[2]!=0:\n",
        "                    list_heb.append(\"וְ\" + num_dict_below_20[num])\n",
        "                else:\n",
        "                    list_heb.append(num_dict_below_20[num])\n",
        " \n",
        "    return list_heb\n",
        " \n",
        " \n",
        "##breaks text to list\n",
        "def break_to_list(text):\n",
        "    \"\"\"\n",
        "    This function receives a string and returns a list of strings with each word from the input text.\n",
        "    \"\"\"\n",
        "    lst = []\n",
        "    for tav in text:\n",
        "        lst.append(tav)\n",
        "    return lst\n",
        " \n",
        "##takes a letter in hebrew and returns the sound in english\n",
        "def English(obj,tzuptzik,last_letter=False):\n",
        "    obj = Hebrew(obj).string\n",
        "    # map the nikud symbols to their corresponding phenoms\n",
        "    nikud_map = {\"ָ\": \"a\", \"ַ\": \"a\", \"ֶ\": \"e\", \"ֵ\": \"e\", \"ִ\": \"i\", \"ְ\": \"\", \"ֹ\": \"o\", \"ֻ\": \"oo\", 'ּ': \"\", 'ֲ': 'a'}\n",
        "    # fixme need create more hebrew phenoms\n",
        " \n",
        "    beged_kefet_shin_sin = {\n",
        "        ############ B\n",
        "        \"בּ\": \"b\",\n",
        "        \"בְּ\": \"b\",\n",
        "        \"בִּ\": \"bi\",\n",
        "        \"בֹּ\": \"bo\",\n",
        "        \"בֵּ\": \"be\",\n",
        "        \"בֶּ\": \"be\",\n",
        "        \"בַּ\": \"ba\",\n",
        "        \"בָּ\": \"ba\",\n",
        "        \"בֻּ\": \"boo\",\n",
        "        ############ G\n",
        "        \"גּ\": \"g\",\n",
        "        \"גְּ\": \"g\",\n",
        "        \"גִּ\": \"gi\",\n",
        "        \"גֹּ\": \"go\",\n",
        "        \"גֵּ\": \"ge\",\n",
        "        \"גֶּ\": \"ge\",\n",
        "        \"גַּ\": \"ga\",\n",
        "        \"גָּ\": \"ga\",\n",
        "        \"גֻּ\": \"goo\",\n",
        "        ########### D\n",
        "        \"דּ\": \"d\",\n",
        "        \"דְּ\": \"d\",\n",
        "        \"דִּ\": \"di\",\n",
        "        \"דֹּ\": \"do\",\n",
        "        \"דֵּ\": \"de\",\n",
        "        \"דֶּ\": \"de\",\n",
        "        \"דַּ\": \"da\",\n",
        "        \"דָּ\": \"da\",\n",
        "        \"דֻּ\": \"doo\",\n",
        "        ########### K\n",
        "        \"כּ\": \"k\",\n",
        "        \"כְּ\": \"k\",\n",
        "        \"כִּ\": \"ki\",\n",
        "        \"כֹּ\": \"ko\",\n",
        "        \"כֵּ\": \"ke\",\n",
        "        \"כֶּ\": \"ke\",\n",
        "        \"כַּ\": \"ka\",\n",
        "        \"כָּ\": \"ka\",\n",
        "        \"כֻּ\": \"koo\",\n",
        "        ############ P\n",
        "        \"פּ\": \"p\",\n",
        "        \"פְּ\": \"p\",\n",
        "        \"פִּ\": \"pi\",\n",
        "        \"פֹּ\": \"po\",\n",
        "        \"פֵּ\": \"pe\",\n",
        "        \"פֶּ\": \"pe\",\n",
        "        \"פַּ\": \"pa\",\n",
        "        \"פָּ\": \"pa\",\n",
        "        \"פֻּ\": \"poo\",\n",
        "        ############ T\n",
        "        \"תּ\": \"t\",\n",
        "        \"תְּ\": \"t\",\n",
        "        \"תִּ\": \"ti\",\n",
        "        \"תֹּ\": \"to\",\n",
        "        \"תֵּ\": \"te\",\n",
        "        \"תֶּ\": \"te\",\n",
        "        \"תַּ\": \"ta\",\n",
        "        \"תָּ\": \"ta\",\n",
        "        \"תֻּ\": \"too\",\n",
        "        ############ S\n",
        "        \"שׂ\": \"s\",\n",
        "        \"שְׂ\": \"s\",\n",
        "        \"שִׂ\": \"si\",\n",
        "        \"שֹׂ\": \"so\",\n",
        "        \"שֵׂ\": \"se\",\n",
        "        \"שֶׂ\": \"se\",\n",
        "        \"שַׂ\": \"sa\",\n",
        "        \"שָׂ\": \"sa\",\n",
        "        \"שֻׂ\": \"soo\",\n",
        "        ########### SH\n",
        "        \"שׁ\": \"sh\",\n",
        "        \"שְׁ\": \"sh\",\n",
        "        \"שִׁ\": \"shi\",\n",
        "        \"שֹׁ\": \"sho\",\n",
        "        \"שֵׁ\": \"she\",\n",
        "        \"שֶׁ\": \"she\",\n",
        "        \"שַׁ\": \"sha\",\n",
        "        \"שָׁ\": \"sha\",\n",
        "        \"שֻׁ\": \"shoo\",\n",
        "    }\n",
        " \n",
        "    vav = {\n",
        "        \"וֵּו\": \"ve\",\n",
        "        \"וּ\": \"oo\",\n",
        "        \"וּו\": \"oo\",\n",
        "        \"וֹ\": \"o\",\n",
        "        \"וֹו\": \"oo\",\n",
        "        \"וְ\": \"ve\",\n",
        "        \"וֱו\": \"ve\",\n",
        "        \"וִ\": \"vi\",\n",
        "        \"וִו\": \"vi\",\n",
        "        \"וַ\": \"va\",\n",
        "        \"וַו\": \"va\",\n",
        "        \"וֶ\": \"ve\",\n",
        "        \"וֶו\": \"ve\",\n",
        "        \"וָ\": \"va\",\n",
        "        \"וָו\": \"va\",\n",
        "        \"וֻ\": \"oo\",\n",
        "        \"וֻו\": \"oo\"\n",
        "    }\n",
        " \n",
        " \n",
        "    letters_map = {\n",
        "        \"א\": \"\",\n",
        "        \"ב\": \"v\",\n",
        "        \"ג\": \"g\",\n",
        "        \"ד\": \"d\",\n",
        "        \"ה\": \"hh\",\n",
        "        \"ו\": \"v\",\n",
        "        \"ז\": \"z\",\n",
        "        \"ח\": \"h\",\n",
        "        \"ט\": \"t\",\n",
        "        \"י\": \"y\",\n",
        "        \"כ\": \"h\",\n",
        "        \"ל\": \"l\",\n",
        "        \"מ\": \"m\",\n",
        "        \"נ\": \"n\",\n",
        "        \"ס\": \"s\",\n",
        "        \"ע\": \"\",\n",
        "        \"פ\": \"f\",\n",
        "        \"צ\": \"ts\",\n",
        "        \"ק\": \"k\",\n",
        "        \"ר\": \"r\",\n",
        "        \"ש\": \"sh\",\n",
        "        \"ת\": \"t\",\n",
        "        \"ן\": \"n\",\n",
        "        \"ם\": \"m\",\n",
        "        \"ף\": \"f\",\n",
        "        \"ץ\": \"ts\",\n",
        "        \"ך\": \"h\",\n",
        "    }\n",
        " \n",
        "    patah_ganav={\n",
        "        \"חַ\": \"ah\",\n",
        "        \"חָ\": \"ah\",\n",
        "        \"הַ\": \"hha\",\n",
        "        \"הָ\": \"hha\",\n",
        "        \"עַ\": \"a\",\n",
        "        \"עָ\": \"a\",\n",
        " \n",
        "    }\n",
        " \n",
        "    tzuptzik_letters={\n",
        "        ##G\n",
        "        \"ג\": \"j\",\n",
        "        \"גְ\": \"j\",\n",
        "        \"גִ\": \"ji\",\n",
        "        \"גֹ\": \"jo\",\n",
        "        \"גֵ\": \"je\",\n",
        "        \"גֶ\": \"je\",\n",
        "        \"גַ\": \"ja\",\n",
        "        \"גָ\": \"ja\",\n",
        "        \"גֻ\": \"joo\",\n",
        "        \"גּ\": \"j\",\n",
        "        \"גְּ\": \"j\",\n",
        "        \"גִּ\": \"ji\",\n",
        "        \"גֹּ\": \"jo\",\n",
        "        \"גֵּ\": \"je\",\n",
        "        \"גֶּ\": \"je\",\n",
        "        \"גַּ\": \"ja\",\n",
        "        \"גָּ\": \"ja\",\n",
        "        \"גֻּ\": \"joo\",\n",
        " \n",
        "        ##ch\n",
        "        \"צ\": \"ch\",\n",
        "        \"צְ\": \"ch\",\n",
        "        \"צִ\": \"chi\",\n",
        "        \"צֹ\": \"cho\",\n",
        "        \"צֵ\": \"che\",\n",
        "        \"צֶ\": \"che\",\n",
        "        \"צַ\": \"cha\",\n",
        "        \"צָ\": \"cha\",\n",
        "        \"צֻ\": \"choo\",\n",
        " \n",
        "        ##Z\n",
        "        \"ז\": \"zh\",\n",
        "        \"זְ\": \"zh\",\n",
        "        \"זִ\": \"zhi\",\n",
        "        \"זֹ\": \"zho\",\n",
        "        \"זֵ\": \"zhe\",\n",
        "        \"זֶ\": \"zhe\",\n",
        "        \"זַ\": \"zha\",\n",
        "        \"זָ\": \"zha\",\n",
        "        \"זֻ\": \"zhoo\",\n",
        "    }\n",
        " \n",
        "    if last_letter:\n",
        "        if obj in patah_ganav:\n",
        "            return patah_ganav[obj]\n",
        " \n",
        "    if tzuptzik==True:\n",
        "        if obj in tzuptzik_letters:\n",
        "            return tzuptzik_letters[obj]\n",
        " \n",
        "    if obj in beged_kefet_shin_sin:\n",
        "        return beged_kefet_shin_sin[obj]\n",
        "    elif obj in vav:\n",
        "        return vav[obj]\n",
        "    else:\n",
        "        lst = break_to_list(obj)\n",
        "        string = \"\"\n",
        "        for item in lst:\n",
        "            if item in letters_map:\n",
        "                string += letters_map[item]\n",
        "            if item in nikud_map:\n",
        "                string += nikud_map[item]\n",
        " \n",
        "        return string\n",
        " \n",
        " \n",
        "##takes hebrew word and turns it into the sound in english\n",
        "def HebWordToEng(word,index):\n",
        "    new_sentence=\"\"\n",
        "    hs = Hebrew(word)\n",
        "    hs = Hebrew(list(hs.graphemes)).string\n",
        "    for i, letter in enumerate(hs):\n",
        " \n",
        "        tzuptzik = False\n",
        "        if i < len(hs) - 1:\n",
        "            if hs[i + 1] == '\\'':\n",
        "                tzuptzik = True\n",
        " \n",
        "        tav = English(letter, tzuptzik, i == len(hs) - 1)\n",
        "        new_sentence += tav\n",
        " \n",
        "    ##clean list:\n",
        "    try:\n",
        "        if new_sentence[-1] == 'y' and new_sentence[-2] == 'y':\n",
        "            new_sentence = new_sentence.replace(\"yy\", \"y\")\n",
        "    except:\n",
        "       pass\n",
        "    return new_sentence\n",
        " \n",
        "##takes hebrew sentence and turns it into english sounds\n",
        "def ARPA(sentence,index=0):\n",
        "    words = sentence.split()\n",
        "    new_sentence = \"\"\n",
        " \n",
        "    for word in words:\n",
        "        ##if number not in string\n",
        "        if not has_number(word):\n",
        "            ret_sentence=HebWordToEng(word,index)\n",
        "            new_sentence+=ret_sentence+\" \"\n",
        " \n",
        "        ##if there is a number:\n",
        "        else:\n",
        "            try:\n",
        "                before_num,num,after_num=split_number_and_string(word)\n",
        " \n",
        "                if has_number(after_num) or has_number(before_num):\n",
        "                    raise(Exception)\n",
        " \n",
        " \n",
        "                ret_sentence = HebWordToEng(before_num, index)\n",
        "                new_sentence += ret_sentence+\" \"\n",
        " \n",
        "                num = [s for s in word if s.isdigit()]\n",
        "                num=\"\".join(num)\n",
        "                num=int(num)\n",
        "                list_of_numbers=NumberToHebrew(num)\n",
        "                for number in list_of_numbers:\n",
        "                    ret_sentence=HebWordToEng(number,index)\n",
        "                    new_sentence += ret_sentence + \" \"\n",
        " \n",
        "                ret_sentence = HebWordToEng(after_num, index)\n",
        "                new_sentence += ret_sentence + \" \"\n",
        "            except:\n",
        "                print(f\"error from split_number_and_string in line:{index} ,the word is {word}\" )\n",
        " \n",
        " \n",
        "    new_sentence = ' '.join(new_sentence.split())\n",
        "    return new_sentence\n",
        " \n",
        " \n",
        "def split_number_and_string(input_string):\n",
        "    # Use regular expression to find any number within the string\n",
        "    match = re.search(r'\\d+', input_string)\n",
        " \n",
        "    if match:\n",
        "        # Extract the number from the string\n",
        "        number = match.group()\n",
        " \n",
        "        # Split the string into two parts: before and after the number\n",
        "        index = match.start()\n",
        "        string_before_number = input_string[:index]\n",
        "        string_after_number = input_string[index + len(number):]\n",
        " \n",
        "        return string_before_number, number, string_after_number\n",
        "    else:\n",
        "        # If no number is found, return None\n",
        "        return None\n",
        " \n",
        " \n",
        "def has_number(input_string):\n",
        "    # Use regular expression to search for any digits within the string\n",
        "    return bool(re.search(r'\\d', input_string))\n",
        " \n",
        "\n",
        " \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "# initialize Tacotron2 with the pretrained model\n",
        "hparams = create_hparams()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GAhZ-94-vC70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Tacotron2 (run this cell every time you change the model)\n",
        "hparams.sampling_rate = 22050 # Don't change this\n",
        "hparams.max_decoder_steps = 1000 # How long the audio will be before it cuts off (1000 is about 11 seconds)\n",
        "hparams.gate_threshold = 0.1 # Model must be 90% sure the clip is over before ending generation (the higher this number is, the more likely that the AI will keep generating until it reaches the Max Decoder Steps)\n",
        "model = Tacotron2(hparams)\n",
        "model.load_state_dict(torch.load(tacotron2_pretrained_model)['state_dict'])\n",
        "_ = model.cuda().eval()"
      ],
      "metadata": {
        "id": "FCyv8MmOvla7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load WaveGlow\n",
        "waveglow = torch.load(waveglow_pretrained_model)['model']\n",
        "waveglow.cuda().eval()\n",
        "for k in waveglow.convinv:\n",
        "    k.float()\n",
        "denoiser = Denoiser(waveglow)"
      ],
      "metadata": {
        "id": "QnW74wETvoIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"בָּנַיי\"\n",
        "sigma = 0.8\n",
        "denoise_strength = 0.1\n",
        "# try to switch raw data to True maybe the results will be better\n",
        "raw_input = False # disables automatic ARPAbet conversion, useful for inputting your own ARPAbet pronounciations or just for testing\n",
        "\n",
        "for i in text.split(\"\\n\"):\n",
        "    if len(i) < 1: continue;\n",
        "    print(i)\n",
        "    if raw_input:\n",
        "        if i[-1] != \";\": i=i+\";\" \n",
        "    else: i = ARPA(i)\n",
        "    print(i)\n",
        "    with torch.no_grad(): # save VRAM by not including gradients\n",
        "        sequence = np.array(text_to_sequence(i, ['english_cleaners']))[None, :]\n",
        "        sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().long()\n",
        "        mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "        plot_data((mel_outputs_postnet.float().data.cpu().numpy()[0],alignments.float().data.cpu().numpy()[0].T))\n",
        "        audio = waveglow.infer(mel_outputs_postnet, sigma=sigma); print(\"\"); ipd.display(ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate))"
      ],
      "metadata": {
        "id": "B5Zb4w8bvog5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}